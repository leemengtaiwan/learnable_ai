# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/data.ipynb (unless otherwise specified).

__all__ = ['logger', 'get_data_root', 'ImageOnlyDataset', 'ImageDataset', 'StickerDataset', 'get_dataset',
           'get_dataloader']


# Cell
import os
import cv2
import torch
import logging
import warnings
import itertools
import multiprocessing
from PIL import Image
from glob import glob
from dotenv import load_dotenv
from easydict import EasyDict as edict
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Dataset

_ = load_dotenv()

logger = logging.getLogger()
logger.setLevel("INFO")


# Cell
def get_data_root(data_root=None):
    data_root = data_root if data_root else os.getenv("DATA_ROOT", ".")
    if not os.path.exists(data_root):
        os.makedirs(data_root)
    return data_root


# Cell
class ImageOnlyDataset(Dataset):
    """常用於生成任務，只回傳圖片而不回傳標籤的 Dataset"""

    def __init__(self, img_label_dataset, img_idx=0):
        self.orig_dataset = img_label_dataset
        self.img_idx = img_idx

    def __len__(self):
        return len(self.orig_dataset)

    def __getitem__(self, idx):
        return self.orig_dataset[idx][self.img_idx]


# Cell
class ImageDataset(Dataset):
    """將指定路徑的圖片讀入並轉換成數據集。各個數據集的轉換由上游自行決定"""

    def __init__(self, root, transform=None, image_exts=None, read="pil"):
        self.root = root
        self.transform = transform if type(transform) is list else transform.transforms
        self.image_exts = image_exts
        self.file_paths = self.get_file_paths()

        if read == "pil":
            self.read_fn = self.pil_read
        else:
            self.read_fn = self.cv2_read
            self.transform = [transforms.ToPILImage()] + self.transform
        self.transform = transforms.Compose(self.transform)

    def __getitem__(self, idx):
        path = self.file_paths[idx]
        image = self.read_fn(path)
        image = self.transform(image)
        return image

    def __len__(self):
        return len(self.file_paths)

    def pil_read(self, file_path):
        with warnings.catch_warnings():
            warnings.simplefilter('ignore', UserWarning)
            return Image.open(file_path).convert("RGB")

    def cv2_read(self, file_path):
        image = cv2.imread(file_path)
        return self.BGR2RGB(image) # `torchvision.utils.save_image` use RGB

    def get_file_paths(self):
        exts = self.image_exts
        if exts:
            exts = [exts] if type(exts) == str else exts
            exts = [e.replace(".", "") for e in exts]
            globs = [glob(os.path.join(self.root, f"*.{e}")) \
                     for e in exts]
            file_paths = list(itertools.chain.from_iterable(globs))
        else:
            file_paths = list(glob(os.path.join(self.root, "*")))

        if not file_paths:
            logging.warning(f"No images available under {self.root}, please check again.")
        else:
            logging.info(f"{len(file_paths)} files found under {self.root}.")

        return file_paths

    def BGR2RGB(self, image):
        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)



# Cell
class StickerDataset(Dataset):
    def __init__(self, sticker_name=None, size=None):
        # files
        self.root_dir = os.path.join(get_data_root(), "stickers")
        self.sticker_name = sticker_name if sticker_name else "kanahei"
        self.size = size if size else (128, 128)
        self.sticker_dir = os.path.join(self.root_dir, self.sticker_name)
        self.image_paths = None

        for dirpath, _, filenames in os.walk(self.root_dir):
            if dirpath == self.sticker_dir:
                self.image_paths = [os.path.join(dirpath, f) for f in filenames]
                break

        if not self.image_paths:
            logging.warning(f"{self.sticker_dir} does not exist.")

        # stats
        self.mean = [0.485, 0.456, 0.406]
        self.std = [0.229, 0.224, 0.225]

        transform = [
            transforms.ColorJitter(.1, .1, .1, .1),
            transforms.RandomHorizontalFlip(),
#             transforms.Resize((224, 256)),
            transforms.Resize(self.size),
#             transforms.CenterCrop(self.size),
            transforms.ToTensor(),
#             transforms.Normalize(mean=self.mean, std=self.std),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]
        self.transform = transforms.Compose(transform)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        with warnings.catch_warnings():
            warnings.simplefilter('ignore', UserWarning)
            image = Image.open(self.image_paths[idx]).convert("RGB")
        image = self.transform(image)
        return image


# Cell
def get_dataset(dataset_name, split="full", size=None, transform=None,
                return_label=True, **kwargs):
    """依據數據集名稱取得 torch Dataset。"""

    dataset_name = dataset_name.lower()
    if dataset_name == "mnist":
        size = size if size else (28, 28)


        transform = transforms.Compose([
            transforms.Resize(size=size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]) if not transform else transform

        root = get_data_root()
        ds_params = dict(root=root, transform=transform, download=True)
        if os.path.exists(os.path.join(root, "MNIST")):
            ds_params['download'] = False
        else:
            ds_params['download'] = True

        if split == "train":
            ds_params['train'] = True
        elif split == "test":
            ds_params['train'] = False
        ds = datasets.MNIST(**ds_params)

        if not return_label:
            ds = ImageOnlyDataset(ds)
    elif dataset_name == "stickers":
        sticker_name = kwargs.get("sticker_name", "kanahei")
        size = size if size else (128, 128)
        ds = StickerDataset(sticker_name, size=size)
    elif dataset_name == 'crypko':
        size = size if size else (64, 64)
        root = os.path.join(get_data_root(), "crypko/faces")
        transform = transforms.Compose([
            transforms.Resize(size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)])
        ds = ImageDataset(root, transform)
    else:
        raise NotImplementedError

    # general
    setattr(ds, "input_shape", (1, *size))
    logging.info(f"{dataset_name} will be resized to {size}.")

    return ds


# Cell
def get_dataloader(dataset, batch_size, shuffle=True, collate_fn=None, drop_last=True, **kwargs):
    use_cuda = torch.cuda.is_available()
    num_workers = multiprocessing.cpu_count() if use_cuda else 1

    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,
                             num_workers=num_workers, collate_fn=collate_fn,
                             drop_last=drop_last, pin_memory=use_cuda)
    return data_loader