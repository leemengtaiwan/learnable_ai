# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/data.ipynb (unless otherwise specified).

__all__ = ['logger', 'get_data_root', 'ImageOnlyDataset', 'get_dataset', 'get_data_loader']


# Cell
import os
import torch
import logging
import multiprocessing
from easydict import EasyDict as edict
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Dataset

logger = logging.getLogger()
logger.setLevel("INFO")


# Cell
def get_data_root(data_root=None):
    data_root = data_root if data_root else os.getenv("DATA_ROOT", ".")
    if not os.path.exists(data_root):
        os.makedirs(data_root)
    return data_root


# Cell
class ImageOnlyDataset(Dataset):
    """常用於生成任務，只回傳圖片而不回傳標籤的 Dataset"""

    def __init__(self, img_label_dataset, img_idx=0):
        self.orig_dataset = img_label_dataset
        self.img_idx = img_idx

    def __len__(self):
        return len(self.orig_dataset)

    def __getitem__(self, idx):
        return self.orig_dataset[idx][self.img_idx]


# Cell
def get_dataset(dataset, split="full", size=None, transform=None, return_label=True,
                  **kwargs):

    dataset = dataset.lower()
    if dataset == "mnist":
        size = size if size else (28, 28)
        logging.info(f"MNIST will be resized to {size}.")

        transform = transforms.Compose([
            transforms.Resize(size=size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ]) if not transform else transform

        root = get_data_root()
        ds_params = dict(root=root, transform=transform, download=True)
        if os.path.exists(os.path.join(root, "MNIST")):
            ds_params['download'] = False

        if split == "train":
            ds_params['train'] = True
        elif split == "test":
            ds_params['train'] = False
        dataset = datasets.MNIST(**ds_params)

        if not return_label:
            dataset = ImageOnlyDataset(dataset)

        setattr(dataset, "input_shape", (1, *size))
    else:
        raise NotImplementedError

    return dataset


# Cell
def get_data_loader(dataset, batch_size, shuffle=True, collate_fn=None, drop_last=True, **kwargs):
    use_cuda = torch.cuda.is_available()
    num_workers = multiprocessing.cpu_count() if use_cuda else 1

    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,
                             num_workers=num_workers, collate_fn=collate_fn,
                             drop_last=drop_last, pin_memory=use_cuda)
    return data_loader