# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/vision.gan.loss.ipynb (unless otherwise specified).

__all__ = ['logger', 'draw_func', 'create_like', 'ones_like', 'zeros_like', 'get_gan_loss_fns', 'get_lsgan_loss_fns',
           'get_wgan_loss_fns', 'get_hinge_loss_fns', 'get_adversarial_loss_fns']


# Cell
import torch
import logging
import numpy as np
import matplotlib.pyplot as plt
from functools import partial
from torch import nn


logger = logging.getLogger()
logger.setLevel("INFO")


# Cell
def draw_func(func, start=-3, end=3.5, step=0.1):
    x = torch.tensor(np.arange(start, end, step))
    y = func(x)
    plt.plot(x, y)


# Cell
def create_like(t, func, on_gpu=False):
    t2 = func(t)
    if on_gpu:
        t2 = t.cuda(t.device.index)
    return t2


def ones_like(t, on_gpu=False):
    return create_like(t, torch.ones_like, on_gpu)


def zeros_like(t, on_gpu=False):
    return create_like(t, torch.zeros_like, on_gpu)


# Cell
def get_gan_loss_fns(is_logits=True, on_gpu=False):
    if is_logits:
        bce = nn.BCEWithLogitsLoss()
    else:
        bce = nn.BCELoss()

    def g_loss_fn(fake_logits, on_gpu=False):
        return bce(fake_logits, ones_like(fake_logits, on_gpu))

    def d_loss_fn(real_logits, fake_logits, on_gpu=False):
        real_loss = bce(real_logits, ones_like(real_logits, on_gpu))
        fake_loss = bce(fake_logits, zeros_like(fake_logits, on_gpu))
        return real_loss, fake_loss

    return g_loss_fn, d_loss_fn


# Cell
def get_lsgan_loss_fns(is_logits=True, on_gpu=False):
    mse = nn.MSELoss()

    def g_loss_fn(fake_logits, on_gpu=False):
        return mse(fake_logits, ones_like(fake_logits, on_gpu))

    def d_loss_fn(real_logits, fake_logits, on_gpu=False):
        real_loss = mse(real_logits, ones_like(real_logits, on_gpu))
        fake_loss = mse(fake_logits, zeros_like(fake_logits, on_gpu))
        return real_loss, fake_loss

    return g_loss_fn, d_loss_fn


# Cell
def get_wgan_loss_fns(is_logits=True, **kwargs):

    def g_loss_fn(fake_logits):
        return -fake_logits.mean()

    def d_loss_fn(real_logits, fake_logits):
        real_loss = -real_logits.mean()
        fake_loss = fake_logits.mean()
        return real_loss, fake_loss

    return g_loss_fn, d_loss_fn


# Cell
def get_hinge_loss_fns(version="geometric_gan", on_gpu=False, **kwargs):

    if version == "geometric_gan":
        def g_loss_fn(fake_logits, **kwargs):
            fake_loss = -fake_logits.mean()
            return fake_loss
    else:
        def g_loss_fn(fake_logits, on_gpu=False):
            fake_loss = torch.max(1 - fake_logits, zeros_like(fake_logits, on_gpu)).mean()
            return fake_loss

    def d_loss_fn(real_logits, fake_logits, on_gpu=False):
        real_loss = torch.max(1 - real_logits, zeros_like(real_logits, on_gpu)).mean()
        fake_loss = torch.max(1 + fake_logits, zeros_like(fake_logits, on_gpu)).mean()
        return real_loss, fake_loss

    return g_loss_fn, d_loss_fn


# Cell
def get_adversarial_loss_fns(_type, is_logits=True, on_gpu=False):
    if _type == "gan":
        fn = get_gan_loss_fns
    elif _type == "lsgan":
        fn = get_lsgan_loss_fns
    elif _type == "wgan":
        fn = get_wgan_loss_fns
    elif _type == "geometric_gan":
        fn = partial(get_hinge_loss_fns, version="geometric_gan")
    elif _type == "hinge_v2":
        fn = partial(get_hinge_loss_fns, version="v2")
    else:
        raise NotImplementedError

    return fn(is_logits=is_logits, on_gpu=on_gpu)