{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from IPython.display import clear_output\n",
    "from nbdev.export import notebook2script\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experimental\n",
    "\n",
    "> description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2tensor(s):\n",
    "    lines = s.split(\"\\n\")\n",
    "    tuples = [l.split(\"\\t\") for l in lines]\n",
    "    tuples = [[int(e) for e in t] for t in tuples]\n",
    "    return torch.tensor(tuples, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#server\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# trainer = Trainer(%)\n",
    "ModelCheckpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "\n",
    "- model architecture\n",
    "    - dcgan\n",
    "    - resnet\n",
    "- SAGAN:\n",
    "    - Spectural norm\n",
    "    - WGAN-GP\n",
    "    - TTUR: 調整 D 以及 G 的 LR Or D 多訓練幾次\n",
    "- 使用WGAN 系列、SNGAN、加 dropout layer、對 input image 加上 noise。\n",
    "- upsample+conv2d 组合代替 transposed_conv2d，可以减少 checkerboard 的产生\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optim: Adam or RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "optimizer_G = torch.optim.RMSprop(generator.parameters(), lr=opt.lr)\n",
    "optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=opt.lr)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Weight clippling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "parser.add_argument(\"--clip_value\", type=float, default=0.01, help=\"lower and upper clip value for disc. weights\")\n",
    "\n",
    "\n",
    "for p in discriminator.parameters():\n",
    "    p.data.clamp_(-opt.clip_value, opt.clip_value)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練指令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "#gan\n",
    "python applications/image_synthesis/train_gan.py\\\n",
    "    --dataset mnist\\\n",
    "    --latent_dim 128\\\n",
    "    --dim 32\\\n",
    "    --channels 1\\\n",
    "    --batch_size 256\n",
    "   \n",
    "# wgan\n",
    "python applications/image_synthesis/train_gan.py\\\n",
    "    --dataset mnist\\\n",
    "    --adversarial_loss_type wgan\\\n",
    "    --latent_dim 128\\\n",
    "    --dim 32\\\n",
    "    --channels 1\\\n",
    "    --batch_size 256\n",
    "    \n",
    "# wgan + weight clip\n",
    "python applications/image_synthesis/train_gan.py\\\n",
    "    --dataset mnist\\\n",
    "    --adversarial_loss_type wgan\\\n",
    "    --discriminator_weight_clip_value 0.01\\\n",
    "    --latent_dim 128\\\n",
    "    --dim 32\\\n",
    "    --channels 1\\\n",
    "    --batch_size 256\n",
    "    \n",
    "# sngan: spectral normalization in d\n",
    "python applications/image_synthesis/train_gan.py\\\n",
    "    --dataset mnist\\\n",
    "    --adversarial_loss_type wgan\\\n",
    "    --discriminator_spectral_norm True\\\n",
    "    --latent_dim 128\\\n",
    "    --dim 32\\\n",
    "    --channels 1\\\n",
    "    --batch_size 256\n",
    "    \n",
    "# hinge\n",
    "python applications/image_synthesis/train_gan.py\\\n",
    "    --dataset mnist\\\n",
    "    --adversarial_loss_type wgan\\\n",
    "    --discriminator_spectral_norm True\\\n",
    "    --latent_dim 128\\\n",
    "    --dim 32\\\n",
    "    --channels 1\\\n",
    "    --batch_size 256\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crykpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python applications/image_synthesis/train_gan.py\\\n",
    "    --dataset crypko\\\n",
    "    --adversarial_loss_type wgan\\\n",
    "    --discriminator_weight_clip_value 0.01\\\n",
    "    --latent_dim 128\\\n",
    "    --dim 64\\\n",
    "    --channels 3\\\n",
    "    --batch_size 512\n",
    "    \n",
    "# sngan\n",
    "python applications/image_synthesis/train_gan.py\\\n",
    "    --dataset crypko\\\n",
    "    --adversarial_loss_type hinge_v1\\\n",
    "    --discriminator_spectral_norm True\\\n",
    "    --latent_dim 128\\\n",
    "    --dim 64\\\n",
    "    --channels 3\\\n",
    "    --batch_size 512\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# wgan + weight clip\n",
    "python applications/image_synthesis/train_gan.py\\\n",
    "    --dataset stickers\\\n",
    "    --adversarial_loss_type wgan\\\n",
    "    --discriminator_weight_clip_value 0.01\\\n",
    "    --latent_dim 128\\\n",
    "    --dim 64\\\n",
    "    --channels 3\\\n",
    "    --batch_size 1024\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python applications/gan/train.py stickers 128 128 3 \\\n",
    "    --batch_size 256 \\\n",
    "    --max_epochs 1\n",
    "\n",
    "\n",
    "python applications/gan/train.py stickers 128 128 3 lsgan \\\n",
    "    --batch_size 512 \\\n",
    "    --max_epochs 100\n",
    "    \n",
    "    \n",
    "python applications/image_generation/train_gan.py crypko 64 64 3 lsgan \\\n",
    "    --batch_size 512 \\\n",
    "    --max_epochs 10000\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "rm -r checkpoints/\n",
    "rm -r lightning_logs/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#server\n",
    "# for _ in range(100):\n",
    "#     python examples/gan/train.py stickers 128 128 3 \\\n",
    "#         --batch_size 256 \\\n",
    "#         --max_epochs 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#server\n",
    "# import torch\n",
    "# from practical_ai.vision.gan.core import GAN\n",
    "# model = GAN.load_from_checkpoint(\"../models/_ckpt_epoch_0.ckpt\")\n",
    "# model = model.eval()\n",
    "\n",
    "# z = torch.randn(1, 128)\n",
    "# img = model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#server\n",
    "# !rm -rf ../models/_ckpt_epoch*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_practical_ai",
   "language": "python",
   "name": "conda_practical_ai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
