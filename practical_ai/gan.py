# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/gan.ipynb (unless otherwise specified).

__all__ = ['logger', 'DIM_CHANNEL_MULTIPLIER', 'KERNEL_SIZE', 'LATENT_DIM', 'DIM', 'CHANNELS', 'NORM', 'BATCH_SIZE',
           'get_n_samplings', 'get_norm2d', 'get_activation', 'UpsampleConv2d', 'UnsqueezeLatent', 'SqueezeLogit',
           'DownsampleConv2d', 'ConvGenerator', 'get_generater', 'get_discriminator', 'GAN']


# Cell
import torch
import logging
import functools
import torchvision
import pytorch_lightning as pl
from torch import nn
from more_itertools import pairwise
from collections import OrderedDict
from .layers import Identity
from .data import get_dataset, get_data_loader
from .gan.loss import get_adversarial_losses_fns


logger = logging.getLogger()
logger.setLevel("INFO")


# Cell
DIM_CHANNEL_MULTIPLIER = 8
KERNEL_SIZE = 4
LATENT_DIM = 128
DIM = 32
CHANNELS = 1
NORM = "batch"
BATCH_SIZE = 32


# Cell
def get_n_samplings(dim):
    return int(torch.log2(torch.tensor(dim, dtype=torch.float32)).item()) - 2


# Cell
def get_norm2d(name):
    if name == "identity":
        return Identity
    elif name == "batch":
        return nn.BatchNorm2d
    elif name == "instance":
        return functools.partial(nn.InstanceNorm2d, affine=True)
    elif name == "layer":
        return lambda num_features: nn.GroupNorm(1, num_features)
    else:
        raise NotImplementedError


# Cell
def get_activation(name):
    if name == "relu":
        return nn.ReLU()
    elif name == "leaky_relu":
        return nn.LeakyReLU(0.2)
    elif name == "tanh":
        return nn.Tanh()
    else:
        raise NotImplementedError


# Cell
class UpsampleConv2d(nn.Sequential):
    """基本上採樣： ConvTransponse2d -> Norm -> Activation"""

    def __init__(self,
                 in_channels,
                 out_channels,
                 kernel_size=KERNEL_SIZE,
                 stride=2,
                 padding=1,
                 norm="batch",
                 act="relu",
                 bias=True):

        layers = [
            nn.ConvTranspose2d(in_channels,
                               out_channels,
                               kernel_size,
                               stride,
                               padding,
                               bias=bias)]

        if norm != "none":
            layers.append(get_norm2d(norm)(out_channels))

        if act not in ["none", "linear"]:
            layers.append(get_activation(act))

        super().__init__(*layers)


# Cell
class UnsqueezeLatent(nn.Module):
    """將 latent vector unsqueeze"""
    def forward(self, x):
        return x[..., None, None]


# Cell
class SqueezeLogit(nn.Module):
    """Squeeze Discriminator logit"""
    def forward(self, x):
        return x.squeeze(-1).squeeze(-1)


# Cell
class DownsampleConv2d(nn.Sequential):
    """基本下採樣： Conv2d -> Norm -> Activation"""

    def __init__(self,
                 in_channels,
                 out_channels,
                 kernel_size=KERNEL_SIZE,
                 stride=2,
                 padding=1,
                 norm="batch",
                 act="leaky_relu",
                 bias=True):

        layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)]

        if norm != "none":
            layers.append(get_norm2d(norm)(out_channels))

        layers.append(get_activation(act))
        super().__init__(*layers)


# Cell
class ConvGenerator(nn.Sequential):
    """將特定維度的潛在向量上採樣到指定圖片大小的生成器"""

    def __init__(self,
                 latent_dim=LATENT_DIM,
                 out_dim=DIM,
                 out_channels=CHANNELS,
                 kernel_size=KERNEL_SIZE,
                 max_channels=None,
                 norm=NORM,
                 act="relu",
                 dim_channel_multiplier=DIM_CHANNEL_MULTIPLIER):
        self.latent_dim = latent_dim
        self.out_dim = out_dim
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.dim_channel_multiplier = dim_channel_multiplier
        self.norm = norm
        self.act = act
        self.max_channels = max_channels if max_channels else self.out_dim * self.dim_channel_multiplier

        # decide appropriate number of upsampling process based on expected output image shape
        self.n_upsamples = get_n_samplings(self.out_dim)

        # projected to spatial extent convolutional repr. with feature maps
        # x.shape == (batch_size, latent_dim)
        layers = [
            UnsqueezeLatent(),
            UpsampleConv2d(in_channels=self.latent_dim,
                           out_channels=self.max_channels,
                           kernel_size=self.kernel_size,
                           stride=1,  # no need to stride in first layer
                           padding=0,  # no padding in first layer
                           norm=self.norm,
                           act=self.act)]

        # upsamples
        # x.shape == (batch_size, max_channels, kernel_size, kernel_size)
        chs = [self.max_channels // (2 ** i) for i in range(self.n_upsamples)]
        chs.append(self.out_channels)

        layers.extend([
            UpsampleConv2d(in_channels=in_ch,
                           out_channels=out_ch,
                           kernel_size=self.kernel_size,
                           stride=2,
                           norm=self.norm if i != self.n_upsamples else "none",
                           act=self.act if i != self.n_upsamples else "tanh",
                           bias=False if i != self.n_upsamples else True)
         for i, (in_ch, out_ch) in enumerate(pairwise(chs), 1)])
        # out.shape == (batch_size, out_channels, out_dim, out_dim)

        # final act: tanh
        # using a bounded activation allowed the model to learn more quickly to
        # saturate and cover the color space of the training distribution.

        super().__init__(*layers)


# Cell
def get_generater(_type):
    if _type == "conv":
        return ConvGenerator
    else:
        raise NotImplementedError

def get_discriminator(_type):
    if _type == "conv":
        return ConvDiscriminator
    else:
        raise NotImplementedError


# Cell
class GAN(pl.LightningModule):
    """基本對抗生成網路"""

    def __init__(self,
                 generator_type="conv",
                 discriminator_type="conv",
                 dataset_name="mnist",
                 adversarial_loss_type="gan",
                 batch_size=BATCH_SIZE,
                 lr=2e-4,
                 beta1=0.5,
                 beta2=0.999,
                 latent_dim=LATENT_DIM,
                 image_shape=(CHANNELS, DIM, DIM),
                 kernel_size=KERNEL_SIZE,
                 norm=NORM,
                 **kwargs):
        super().__init__()
        self.generator_type = generator_type
        self.discriminator_type = discriminator_type
        self.dataset_name = dataset_name
        self.adversarial_loss_type = adversarial_loss_type
        self.batch_size = batch_size
        self.latent_dim = latent_dim
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.image_shape = image_shape
        self.kernel_size = kernel_size
        self.norm = norm

        # adversarial losses
        self.g_loss_fn, self.d_loss_fn = \
            get_adversarial_losses_fns(self.adversarial_loss_type)


        assert self.image_shape[-1] == self.image_shape[-2]
        self.channels, self.dim = self.image_shape[0], self.image_shape[-1]

        # initialize networks
        g = get_generater(self.generator_type)
        self.generator = g(latent_dim=self.latent_dim,
                           out_dim=self.dim,
                           out_channels=self.channels,
                           kernel_size=self.kernel_size,
                           norm=self.norm)

        d = get_discriminator(self.discriminator_type)
        self.discriminator = d(in_channels=self.channels,
                               in_dim=self.dim,
                               norm=self.norm,
                               kernel_size=self.kernel_size)

        # cache for generated images
        self.generated_images = None
        self.last_real_images = None

    def prepare_data(self):
        self.train_dataset = get_dataset(dataset=self.dataset_name,
                                         split="train",
                                         size=(self.dim, self.dim),
                                         return_label=False)

        self.valid_dataset = get_dataset(dataset=self.dataset_name,
                                         split="valid",
                                         size=(self.dim, self.dim),
                                         return_label=False)

    def train_dataloader(self):
        return get_data_loader(self.train_dataset, batch_size=self.batch_size)

    def configure_optimizers(self):
        self.g_optim = torch.optim.Adam(self.generator.parameters(),
                                        lr=self.lr,
                                        betas=(self.beta1, self.beta2))
        self.d_optim = torch.optim.Adam(self.discriminator.parameters(),
                                        lr=self.lr,
                                        betas=(self.beta1, self.beta2))
        return [self.d_optim, self.g_optim], []

    def get_latent_vectors(self, n=8, on_gpu=True):
        z = torch.randn(n, self.latent_dim)
        if on_gpu:
            z = z.cuda(self.last_real_images.device.index)
        return z

    def training_step(self, batch, batch_idx, optimizer_idx):
        self.last_real_images = real_images = batch
        z = self.get_latent_vectors(on_gpu=self.on_gpu)

        # discriminator
        if optimizer_idx == 0:
            fake_images = self.generator(z).detach()
            real_logits = self.discriminator(real_images)
            fake_logits = self.discriminator(fake_images)

            d_real_loss, d_fake_loss = self.d_loss_fn(real_logits, fake_logits,
                                                      on_gpu=self.on_gpu)
            d_loss = d_real_loss + d_fake_loss

            # TODO: gradient penality

            tqdm_dict = {'d_loss': d_loss}
            output = OrderedDict({
                'loss': d_loss,
                'progress_bar': tqdm_dict,
                'log': tqdm_dict
            })
            return output

        # generator
        if optimizer_idx == 1:
            fake_images = self.generateed_images = self.generator(z)
            fake_logits = self.discriminator(fake_images)
            g_loss = self.g_loss_fn(fake_logits)

            tqdm_dict = {'g_loss': g_loss}
            output = OrderedDict({
                'loss': g_loss,
                'progress_bar': tqdm_dict,
                'log': tqdm_dict
            })
            return output

    def forward(self, z):
        return self.generator(z)

    def on_epoch_end(self):
        z = self.get_latent_vectors(on_gpu=self.on_gpu)
        sample_images = self.generator(z)
        grid = torchvision.utils.make_grid(sample_images)
        self.logger.experiment.add_image('sample_images', grid, self.current_epoch)