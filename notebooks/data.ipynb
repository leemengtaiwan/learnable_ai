{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from IPython.display import clear_output\n",
    "from nbdev.export import notebook2script\n",
    "from dotenv import load_dotenv\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import multiprocessing\n",
    "from easydict import EasyDict as edict\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "\n",
    "> 下載、載入並前處理數據並建立 Dataset 和 DataLoader 之模組。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得數據根目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_data_root(data_root=None):\n",
    "    data_root = data_root if data_root else os.getenv(\"DATA_ROOT\", \".\")\n",
    "    if not os.path.exists(data_root):\n",
    "        os.makedirs(data_root)\n",
    "    return data_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predefined_data_root = os.getenv(\"DATA_ROOT\")\n",
    "\n",
    "if predefined_data_root:\n",
    "    assert predefined_data_root == get_data_root()\n",
    "else:\n",
    "    assert get_data_root(\"tmp\") == \"tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_root()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Dataset / DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageOnlyDataset(Dataset):\n",
    "    \"\"\"常用於生成任務，只回傳圖片而不回傳標籤的 Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, img_label_dataset, img_idx=0):\n",
    "        self.orig_dataset = img_label_dataset\n",
    "        self.img_idx = img_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.orig_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.orig_dataset[idx][self.img_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dataset(dataset, split=\"full\", size=None, transform=None, return_label=True, \n",
    "                  **kwargs):\n",
    "    \n",
    "    dataset = dataset.lower()\n",
    "    if dataset == \"mnist\":\n",
    "        size = size if size else (28, 28)\n",
    "        logging.info(f\"MNIST will be resized to {size}.\")\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(size=size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ]) if not transform else transform\n",
    "        \n",
    "        root = get_data_root()\n",
    "        ds_params = dict(root=root, transform=transform, download=True)\n",
    "        if os.path.exists(os.path.join(root, \"MNIST\")):\n",
    "            ds_params['download'] = False\n",
    "        \n",
    "        if split == \"train\":\n",
    "            ds_params['train'] = True\n",
    "        elif split == \"test\":\n",
    "            ds_params['train'] = False\n",
    "        dataset = datasets.MNIST(**ds_params)\n",
    "        \n",
    "        if not return_label:\n",
    "            dataset = ImageOnlyDataset(dataset)\n",
    "            \n",
    "        setattr(dataset, \"input_shape\", (1, *size))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定數據集名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MNIST will be resized to (28, 28).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = get_dataset(\"mnist\")\n",
    "x = mnist[0]\n",
    "\n",
    "assert mnist.input_shape == (1, 28, 28)  # CHW\n",
    "assert len(mnist) == 60_000\n",
    "assert len(x) == 2\n",
    "mnist.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切割數據集、改變圖片大小並不回傳標籤\n",
    "生成任務有時不需要使用標籤資訊。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MNIST will be resized to (32, 32).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 32, 32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = (32, 32)\n",
    "mnist_test = get_dataset(\"mnist\", split=\"test\", size=size, return_label=False)\n",
    "x = mnist_test[0]\n",
    "\n",
    "assert mnist_test.input_shape == (1, *size)\n",
    "assert len(mnist_test) == 10_000\n",
    "assert len(x) == 1\n",
    "mnist_test.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_data_loader(dataset, batch_size, shuffle=True, collate_fn=None, drop_last=True, **kwargs):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    num_workers = multiprocessing.cpu_count() if use_cuda else 1\n",
    "    \n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, \n",
    "                             num_workers=num_workers, collate_fn=collate_fn, \n",
    "                             drop_last=drop_last, pin_memory=use_cuda)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "mnist_data_loader = get_data_loader(mnist, batch_size=batch_size)\n",
    "batch = next(iter(mnist_data_loader))\n",
    "\n",
    "assert len(batch) == 2\n",
    "assert batch[0].shape[0] == batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "notebook2script()\n",
    "clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_practical_ai",
   "language": "python",
   "name": "conda_practical_ai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
