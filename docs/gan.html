---

title: gan

keywords: fastai
sidebar: home_sidebar

summary: "對抗生成網路（Generative Adversarial Network）的相關模組。"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/gan.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Utilities">Utilities<a class="anchor-link" href="#Utilities">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_n_samplings" class="doc_header"><code>get_n_samplings</code><a href="https://github.com/leemengtaiwan/practical_ai/tree/master/practical_ai/gan.py#L26" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_n_samplings</code>(<strong><code>dim</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dim</span> <span class="o">=</span> <span class="mi">32</span>
<span class="k">assert</span> <span class="n">get_n_samplings</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_norm2d" class="doc_header"><code>get_norm2d</code><a href="https://github.com/leemengtaiwan/practical_ai/tree/master/practical_ai/gan.py#L31" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_norm2d</code>(<strong><code>name</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">norm</span> <span class="o">=</span> <span class="n">get_norm2d</span><span class="p">(</span><span class="s2">&quot;identity&quot;</span><span class="p">)</span>
<span class="n">norm</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>practical_ai.layers.Identity</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_activation" class="doc_header"><code>get_activation</code><a href="https://github.com/leemengtaiwan/practical_ai/tree/master/practical_ai/gan.py#L45" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_activation</code>(<strong><code>name</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">act</span> <span class="o">=</span> <span class="n">get_activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
<span class="n">act</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ReLU()</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Modules">Modules<a class="anchor-link" href="#Modules">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UpsampleConv2d" class="doc_header"><code>class</code> <code>UpsampleConv2d</code><a href="https://github.com/leemengtaiwan/practical_ai/tree/master/practical_ai/gan.py#L57" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UpsampleConv2d</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>kernel_size</code></strong>=<em><code>4</code></em>, <strong><code>stride</code></strong>=<em><code>2</code></em>, <strong><code>padding</code></strong>=<em><code>1</code></em>, <strong><code>norm</code></strong>=<em><code>'batch'</code></em>, <strong><code>act</code></strong>=<em><code>'relu'</code></em>, <strong><code>bias</code></strong>=<em><code>True</code></em>) :: <code>Sequential</code></p>
</blockquote>
<p>ConvTransponse2d -&gt; Normalization -&gt; Activation</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>一般使用： Transposed Conv -&gt; Norm -&gt; Act</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="n">upconv</span> <span class="o">=</span> <span class="n">UpsampleConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">upconv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">upconv</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
<span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">h</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">w</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">upconv</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>UpsampleConv2d(
  (0): ConvTranspose2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU()
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>單純上採樣，不使用 Norm 以及非線性 activation</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">linear_acts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">act</span> <span class="ow">in</span> <span class="n">linear_acts</span><span class="p">:</span>
    <span class="n">upconv_linear</span> <span class="o">=</span> <span class="n">UpsampleConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="n">act</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">upconv_linear</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">upconv_linear</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>UpsampleConv2d(
  (0): ConvTranspose2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
)
UpsampleConv2d(
  (0): ConvTranspose2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnsqueezeLatent" class="doc_header"><code>class</code> <code>UnsqueezeLatent</code><a href="https://github.com/leemengtaiwan/practical_ai/tree/master/practical_ai/gan.py#L88" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnsqueezeLatent</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">UnsqueezeLatent</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SqueezeLogit" class="doc_header"><code>class</code> <code>SqueezeLogit</code><a href="https://github.com/leemengtaiwan/practical_ai/tree/master/practical_ai/gan.py#L94" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SqueezeLogit</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">dim</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">SqueezeLogit</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DownsampleConv2d" class="doc_header"><code>class</code> <code>DownsampleConv2d</code><a href="https://github.com/leemengtaiwan/practical_ai/tree/master/practical_ai/gan.py#L100" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DownsampleConv2d</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>kernel_size</code></strong>=<em><code>4</code></em>, <strong><code>stride</code></strong>=<em><code>2</code></em>, <strong><code>padding</code></strong>=<em><code>1</code></em>, <strong><code>norm</code></strong>=<em><code>'batch'</code></em>, <strong><code>act</code></strong>=<em><code>'leaky_relu'</code></em>, <strong><code>bias</code></strong>=<em><code>True</code></em>) :: <code>Sequential</code></p>
</blockquote>
<p>Conv2D -&gt; Normalization -&gt; Activation</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>基本下採樣</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="n">downconv</span> <span class="o">=</span> <span class="n">DownsampleConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">downconv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">h</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">w</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Generator">Generator<a class="anchor-link" href="#Generator">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ConvGenerator" class="doc_header"><code>class</code> <code>ConvGenerator</code><a href="https://github.com/leemengtaiwan/practical_ai/tree/master/practical_ai/gan.py#L123" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ConvGenerator</code>(<strong><code>latent_dim</code></strong>=<em><code>128</code></em>, <strong><code>out_dim</code></strong>=<em><code>32</code></em>, <strong><code>out_channels</code></strong>=<em><code>1</code></em>, <strong><code>kernel_size</code></strong>=<em><code>4</code></em>, <strong><code>max_channels</code></strong>=<em><code>None</code></em>, <strong><code>norm</code></strong>=<em><code>'batch'</code></em>, <strong><code>act</code></strong>=<em><code>'relu'</code></em>, <strong><code>dim_channel_multiplier</code></strong>=<em><code>8</code></em>) :: <code>Sequential</code></p>
</blockquote>
<p>將輸入維度的隨機向量上採樣到指定大小圖片的生成器</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="k">for</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">out_ch</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">ConvGenerator</span><span class="p">(</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_ch</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span>
<span class="n">g</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ConvGenerator(
  (0): UnsqueezeLatent()
  (1): UpsampleConv2d(
    (0): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): UpsampleConv2d(
    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): UpsampleConv2d(
    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): UpsampleConv2d(
    (0): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): Tanh()
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Discriminator">Discriminator<a class="anchor-link" href="#Discriminator">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ConvDiscriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;將特定大小圖片下採樣的辨識器&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                 <span class="n">in_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
                 <span class="n">norm</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span>
                 <span class="n">kernel_size</span><span class="o">=</span><span class="n">KERNEL_SIZE</span><span class="p">,</span>
                 <span class="n">max_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">dim_channel_multiplier</span><span class="o">=</span><span class="n">DIM_CHANNEL_MULTIPLIER</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span> <span class="o">=</span> <span class="n">in_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_downsamples</span> <span class="o">=</span> <span class="n">get_n_samplings</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_channel_multiplier</span> <span class="o">=</span> <span class="n">dim_channel_multiplier</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_channels</span> <span class="o">=</span> <span class="n">max_channels</span> <span class="k">if</span> <span class="n">max_channels</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_channel_multiplier</span>
        
        <span class="c1"># downsample</span>
        <span class="n">chs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span><span class="p">]</span>
        <span class="n">chs</span> <span class="o">+=</span> <span class="nb">sorted</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">max_channels</span> <span class="o">//</span> <span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_downsamples</span><span class="p">)])</span>
        
        <span class="c1"># x.shape == (batch_size, in_channels, in_dim, in_dim)</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">DownsampleConv2d</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> 
                             <span class="n">out_ch</span><span class="p">,</span> 
                             <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> 
                             <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                             <span class="n">norm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
                             <span class="n">bias</span><span class="o">=</span><span class="kc">False</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">True</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pairwise</span><span class="p">(</span><span class="n">chs</span><span class="p">),</span> <span class="mi">1</span><span class="p">)]</span>
        
        <span class="c1"># compute logits</span>
        <span class="c1"># x.shape == (batch_size, max_channels, kernel_size, kernel_size)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">chs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">),</span>
            <span class="n">SqueezeLogit</span><span class="p">()</span>
        <span class="p">])</span>
        <span class="c1"># out.shape == (batch_size, 1)</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="k">for</span> <span class="n">in_ch</span><span class="p">,</span> <span class="n">in_dim</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">]):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">in_ch</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">ConvDiscriminator</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">d</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ConvDiscriminator(
  (0): DownsampleConv2d(
    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.2)
  )
  (1): DownsampleConv2d(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2)
  )
  (2): DownsampleConv2d(
    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2)
  )
  (3): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))
  (4): SqueezeLogit()
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># from practical_ai.data import get_data_loader, get_dataset</span>
<span class="c1"># dataset = get_dataset(&quot;mnist&quot;, split=&quot;train&quot;)</span>
<span class="c1"># data_loader = get_data_loader(dataset, batch_size=4)</span>



<span class="c1"># from torch.utils.tensorboard import SummaryWriter</span>
<span class="c1"># import torchvision</span>

<span class="c1"># # default `log_dir` is &quot;runs&quot; - we&#39;ll be more specific here</span>
<span class="c1"># writer = SummaryWriter(&#39;runs/test&#39;)</span>

<span class="c1"># dataiter = iter(data_loader)</span>
<span class="c1"># images, labels = dataiter.next()</span>

<span class="c1"># img_grid = torchvision.utils.make_grid(images)</span>
<span class="c1"># writer.add_image(&#39;four_mnist_images&#39;, img_grid)</span>

<span class="c1"># images.shape</span>

<span class="c1"># z = torch.randn(1, latent_dim, 1, 1)</span>

<span class="c1"># writer.add_graph(g, z)</span>
<span class="c1"># writer.close()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Generative-Adversarial-Network">Generative Adversarial Network<a class="anchor-link" href="#Generative-Adversarial-Network">&#182;</a></h2>
</div>
</div>
</div>
    {% endraw %}
</div>
 

