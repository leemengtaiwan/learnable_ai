{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再現整個 Fashion MNIST 訓練過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from practical_ai.data import get_dataset, get_data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 引入已實現好的模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "lib_path = \"/home/ec2-user/SageMaker/workspace/DCGAN-LSGAN-WGAN-GP-DRAGAN-Pytorch\"\n",
    "sys.path = [lib_path] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = edict(\n",
    "    dataset=\"mnist\",\n",
    "    batch_size=32,\n",
    "    gradient_penalty_mode='none',\n",
    "    adversarial_loss_mode='gan',\n",
    "    z_dim=128,\n",
    "    lr=0.0002,\n",
    "    beta_1=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, device(type='cuda'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "use_gpu, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_G_upsamplings = n_D_downsamplings = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MNIST will be resized to (28, 28).\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(\"mnist\")\n",
    "data_loader = get_data_loader(dataset, batch_size=args.batch_size, \n",
    "                                pin_memory=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import module\n",
    "import torchprob as gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvDiscriminator(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (4): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# setup the normalization function for discriminator\n",
    "if args.gradient_penalty_mode == 'none':\n",
    "    d_norm = 'batch_norm'\n",
    "else:  # cannot use batch normalization with gradient penalty\n",
    "    d_norm = args.gradient_penalty_d_norm\n",
    "\n",
    "# networks\n",
    "\n",
    "G = module.ConvGenerator(args.z_dim, 3, n_upsamplings=3).to(device)\n",
    "D = module.ConvDiscriminator(dataset.input_shape[-1], n_downsamplings=3, norm=d_norm).to(device)\n",
    "# print(G)\n",
    "print(D)\n",
    "\n",
    "# # adversarial_loss_functions\n",
    "# d_loss_fn, g_loss_fn = gan.get_adversarial_losses_fn(args.adversarial_loss_mode)\n",
    "\n",
    "# # optimizer\n",
    "# G_optimizer = torch.optim.Adam(G.parameters(), lr=args.lr, betas=(args.beta_1, 0.999))\n",
    "# D_optimizer = torch.optim.Adam(D.parameters(), lr=args.lr, betas=(args.beta_1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改成 Pytorch Lightning 格式\n",
    "- 加上 TensorBoard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練李宏毅的 Anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "from collections import OrderedDict\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, input_shape):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "#         def block(in_feat, out_feat, normalize=True):\n",
    "#             layers = [nn.Linear(in_feat, out_feat)]\n",
    "#             if normalize:\n",
    "#                 layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "#             layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "#             return layers\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             *block(latent_dim, 128, normalize=False),\n",
    "#             *block(128, 256),\n",
    "#             *block(256, 512),\n",
    "#             *block(512, 1024),\n",
    "#             *block(1024, np.prod(img_shape)),\n",
    "#         )\n",
    "\n",
    "#         self.model\n",
    "\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "        \n",
    "#         img = self.model(z)\n",
    "#         img = img.view(img.size(0), *self.img_shape)\n",
    "#         return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "input_shape = (1, 28, 28)\n",
    "\n",
    "\n",
    "g = Generator(latent_dim=latent_dim, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_channels = 1024\n",
    "base_output_shape = 4\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=512, k)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4 -> 8 -> 16 -> 28\n",
    "512 -> 256 -> 128 -> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 3\n",
    "z = torch.randn(bs, 100)\n",
    "out = g(z)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=128, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (3): BatchNorm1d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (6): BatchNorm1d(512, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (8): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (9): BatchNorm1d(1024, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (11): Linear(in_features=1024, out_features=784, bias=True)\n",
       "  (12): BatchNorm1d(784, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(self.img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        validity = self.model(img.view(img.size(0), -1))\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4853],\n",
       "        [0.4854],\n",
       "        [0.4855]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Discriminator(img_shape)\n",
    "d(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    def __init__(self, gan_type, hparams):\n",
    "        super(GAN, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        # networks\n",
    "        self.gan_type = gan_type\n",
    "        if self.gan_type == \"gan\":\n",
    "            self.generator = Generator(hparams.latent_dim, )\n",
    "            self.discriminator = Discriminator(mnist_shape)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        \n",
    "        self.hparams = hparams\n",
    "        self.data_root = data_root = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "        # network\n",
    "        mnist_shape = (1, 28, 28)\n",
    "        \n",
    "\n",
    "        # cache\n",
    "        self.generated_imgs = None\n",
    "        self.last_imgs = None\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        imgs, _ = batch\n",
    "        self.last_imgs = imgs\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            # sample noise\n",
    "            z = torch.randn(imgs.shape[0], self.hparams.latent_dim)\n",
    "\n",
    "            if self.on_gpu:\n",
    "                z = z.cuda(imgs.device.index)\n",
    "\n",
    "            # generate images\n",
    "            self.generated_imgs = self.forward(z)\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "            if self.on_gpu:\n",
    "                valid = valid.cuda(imgs.device.index)\n",
    "            \n",
    "            g_loss = self.adversarial_loss(self.discriminator(self.generated_imgs), valid)\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(imgs.shape[0], 1)\n",
    "            if self.on_gpu:\n",
    "                valid = valid.cuda(imgs.device.index)\n",
    "\n",
    "            real_loss = self.adversarial_loss(self.discriminator(imgs), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(imgs.shape[0], 1)\n",
    "            if self.on_gpu:\n",
    "                fake = fake.cuda(imgs.device.index)\n",
    "            \n",
    "            fake_loss = self.adversarial_loss(\n",
    "                self.discriminator(self.generated_imgs.detach()), fake)\n",
    "            \n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict,\n",
    "            })\n",
    "            return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # prepare transforms standard to MNIST\n",
    "        \n",
    "        if not os.path.exists(self.data_root):\n",
    "            os.makedirs(self.data_root)\n",
    "        MNIST(self.data_root, train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        \n",
    "        dataset = MNIST(self.data_root, train=True, download=False, transform=transform)\n",
    "        self.train_dataset, self.val_dataset = random_split(dataset, [55000, 5000])\n",
    "\n",
    "        return DataLoader(self.train_dataset, batch_size=self.hparams.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.hparams.batch_size)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        z = torch.randn(self.last_imgs.shape[0], self.hparams.latent_dim)\n",
    "        z = z[:32]\n",
    "        if self.on_gpu:\n",
    "            z = z.cuda(self.last_imgs.device.index)\n",
    "\n",
    "        # log sampled images\n",
    "        sample_imgs = self.forward(z)\n",
    "        grid = torchvision.utils.make_grid(sample_imgs)\n",
    "        self.logger.experiment.add_image('generated_images', grid, self.current_epoch + 1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(b1=0.5, b2=0.999, batch_size=1024, latent_dim=100, lr=0.0002)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'batch_size': 1024,\n",
    "    'lr': 0.0002,\n",
    "    'b1': 0.5,\n",
    "    'b2': 0.999,\n",
    "    'latent_dim': LATENT_DIM\n",
    "}\n",
    "hparams = Namespace(**args)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432b811d0c56481582274a45b071bce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GAN(hparams, generator=)\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, log_gpu_memory=True)   \n",
    "\n",
    "trainer.fit(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_practical_ai",
   "language": "python",
   "name": "conda_practical_ai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
