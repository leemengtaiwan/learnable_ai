# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/gan.ipynb (unless otherwise specified).

__all__ = ['logger', 'DIM_CHANNEL_MULTIPLIER', 'KERNEL_SIZE', 'get_n_samplings', 'get_norm2d', 'get_activation',
           'UpsampleConv2d', 'UnsqueezeLatent', 'SqueezeLogit', 'DownsampleConv2d', 'ConvGenerator']


# Cell
import torch
import logging
import functools
from torch import nn
from more_itertools import pairwise
from .layers import Identity


logger = logging.getLogger()
logger.setLevel("INFO")


# Cell
DIM_CHANNEL_MULTIPLIER = 8
KERNEL_SIZE = 4


# Cell
def get_n_samplings(dim):
    return int(torch.log2(torch.tensor(dim, dtype=torch.float32)).item()) - 2


# Cell
def get_norm2d(name):
    if name == "identity":
        return Identity
    elif name == "batch":
        return nn.BatchNorm2d
    elif name == "instance":
        return functools.partial(nn.InstanceNorm2d, affine=True)
    elif name == "layer":
        return lambda num_features: nn.GroupNorm(1, num_features)
    else:
        raise NotImplementedError


# Cell
def get_activation(name):
    if name == "relu":
        return nn.ReLU()
    elif name == "leaky_relu":
        return nn.LeakyReLU(0.2)
    elif name == "tanh":
        return nn.Tanh()
    else:
        raise NotImplementedError


# Cell
class UpsampleConv2d(nn.Sequential):
    """ConvTransponse2d -> Normalization -> Activation"""

    def __init__(self,
                 in_channels,
                 out_channels,
                 kernel_size=KERNEL_SIZE,
                 stride=2,
                 padding=1,
                 norm="batch",
                 act="relu",
                 bias=True):

        layers = [
            nn.ConvTranspose2d(in_channels,
                               out_channels,
                               kernel_size,
                               stride,
                               padding,
                               bias=bias)]

        if norm != "none":
            layers.append(get_norm2d(norm)(out_channels))

        if act not in ["none", "linear"]:
            layers.append(get_activation(act))

        super().__init__(*layers)


# Cell
class UnsqueezeLatent(nn.Module):
    def forward(self, x):
        return x[..., None, None]


# Cell
class SqueezeLogit(nn.Module):
    def forward(self, x):
        return x.squeeze(-1).squeeze(-1)


# Cell
class DownsampleConv2d(nn.Sequential):
    """Conv2D -> Normalization -> Activation"""

    def __init__(self,
                 in_channels,
                 out_channels,
                 kernel_size=KERNEL_SIZE,
                 stride=2,
                 padding=1,
                 norm="batch",
                 act="leaky_relu",
                 bias=True):

        layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)]

        if norm != "none":
            layers.append(get_norm2d(norm)(out_channels))

        layers.append(get_activation(act))
        super().__init__(*layers)


# Cell
class ConvGenerator(nn.Sequential):
    """將輸入維度的隨機向量上採樣到指定大小圖片的生成器"""

    def __init__(self,
                 latent_dim=128,
                 out_dim=32,
                 out_channels=1,
                 kernel_size=4,
                 max_channels=None,
                 norm='batch',
                 act="relu",
                 dim_channel_multiplier=DIM_CHANNEL_MULTIPLIER):
        self.latent_dim = latent_dim
        self.out_dim = out_dim
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.dim_channel_multiplier = dim_channel_multiplier
        self.norm = norm
        self.act = act
        self.max_channels = max_channels if max_channels else self.out_dim * self.dim_channel_multiplier

        # decide appropriate number of upsampling process based on expected output image shape
        self.n_upsamples = get_n_samplings(self.out_dim)

        # projected to spatial extent convolutional repr. with feature maps
        # x.shape == (batch_size, latent_dim)
        layers = [
            UnsqueezeLatent(),
            UpsampleConv2d(in_channels=self.latent_dim,
                           out_channels=self.max_channels,
                           kernel_size=self.kernel_size,
                           stride=1,  # no need to stride in first layer
                           padding=0,  # no padding in first layer
                           norm=self.norm,
                           act=self.act)]

        # upsamples
        # x.shape == (batch_size, max_channels, kernel_size, kernel_size)
        chs = [self.max_channels // (2 ** i) for i in range(self.n_upsamples)]
        chs.append(self.out_channels)

        layers.extend([
            UpsampleConv2d(in_channels=in_ch,
                           out_channels=out_ch,
                           kernel_size=self.kernel_size,
                           stride=2,
                           norm=self.norm if i != self.n_upsamples else "none",
                           act=self.act if i != self.n_upsamples else "tanh",
                           bias=False if i != self.n_upsamples else True)
         for i, (in_ch, out_ch) in enumerate(pairwise(chs), 1)])
        # out.shape == (batch_size, out_channels, out_dim, out_dim)

        # final act: tanh
        # using a bounded activation allowed the model to learn more quickly to
        # saturate and cover the color space of the training distribution.

        super().__init__(*layers)